{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영화별 줄거리 내  키워드 추출<br>\n",
    "줄거리 기준 : 네이버 영화 페이지의 줄거리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\leejb\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tqdm\\autonotebook\\__init__.py:18: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import re\n",
    "from konlpy.tag import Okt, Kkma, Komoran\n",
    "#from keras.preprocessing.text import Tokenizer\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import networkx\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.models import word2vec\n",
    "#from difflib import ndiff\n",
    "\n",
    "import os\n",
    "os.environ['JAVA_OPTS'] = 'Xmx8192m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_execute = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./naver_movie_dataset/naver_movie_dataset_1227.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['plot'].isnull()].index, inplace=True)\n",
    "\n",
    "df['plot'] = df['plot'].apply(str)\n",
    "plots = df['plot'].copy()#pd.Series(df['plot'])\n",
    "\n",
    "df['plot'] = list(map(lambda x:re.sub(\"\\‘[가-힣 ]+\\’(\\([가-힣 ]+\\))?[^\\s]*\",\" \",x),df['plot']))\n",
    "df['plot'] = list(map(lambda x:re.sub(\"[가-힣]+ [가-힣]+ {0,1}\\([가-힣 ]+\\)[^\\s]*\",\" \",x), df['plot']))\n",
    "\n",
    "for idx in tqdm(df.index):\n",
    "    chars1, chars2 = [],[]\n",
    "    \n",
    "    chars1 = list(set([s[1:-1] for s in re.findall(\"\\‘[가-힣 ]+\\’\", plots[idx])]))\n",
    "    if chars1:\n",
    "        if len(chars1) == 1:\n",
    "            regex1 = ''.join(list(set([s[1:-1] for s in re.findall(\"\\‘[가-힣 ]+\\’\", plots[idx])])))\n",
    "        else:\n",
    "            regex1 = '|'.join(list(set([s[1:-1] for s in re.findall(\"\\‘[가-힣 ]+\\’\", plots[idx])])))\n",
    "        #print(regex1)\n",
    "        plots[idx] = re.sub('(%s)[^\\s]'%(regex1),' ',df.loc[idx,'plot'])\n",
    "\n",
    "    chars2 = ''.join(re.findall('[가-힣]+ [가-힣]+ {0,1}\\([가-힣 ]+\\)',plots[idx]))\n",
    "    if chars2:\n",
    "        regex2 = '|'.join(map(str.strip, re.compile('\\([가-힣 ]+\\)').split(chars2)[:-1]))\n",
    "        regex2 += '|'+' '.join(regex2.split('|')).replace(' ','|')\n",
    "        #print(regex2)\n",
    "        plots[idx] = re.sub('(%s)[^\\s]'%(regex2),' ',df.loc[idx,'plot'])\n",
    "\n",
    "df['plot'] = plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(len(df['plot']))\n",
    "df['plot'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['plot'] = df['plot'].str.replace('\\r\\xa0', ' ')\n",
    "display(df[df['plot'].str.contains('\\r')].index)\n",
    "df['plot'] = df['plot'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 .][^\\s]+\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['plot'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "okt, kkma, kmr = Okt(), Kkma(), Komoran()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어 출현 빈도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988de2d671c74650b8cad6d6d09fc5f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10255), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cnt = Counter()\n",
    "\n",
    "for plot in tqdm(df['plot']):\n",
    "    for word,tag in kmr.pos(plot):\n",
    "        if tag in ['NNP', 'NNG', 'VV']:\n",
    "            if not cnt[(word,tag)]:\n",
    "                cnt[(word,tag)] = 1\n",
    "            else:\n",
    "                cnt[(word,tag)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnt.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>되</td>\n",
       "      <td>VV</td>\n",
       "      <td>16300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>하</td>\n",
       "      <td>VV</td>\n",
       "      <td>8294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>있</td>\n",
       "      <td>VV</td>\n",
       "      <td>7486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>위하</td>\n",
       "      <td>VV</td>\n",
       "      <td>6095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>자신</td>\n",
       "      <td>NNG</td>\n",
       "      <td>5437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  tag    cnt\n",
       "0    되   VV  16300\n",
       "1    하   VV   8294\n",
       "2    있   VV   7486\n",
       "3   위하   VV   6095\n",
       "4   자신  NNG   5437"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_df = pd.DataFrame(np.hstack(np.array(cnt.most_common())[:,0]).reshape(-1,2),\n",
    "                     columns=['word','tag'])\n",
    "cnt_df['cnt'] = np.array(cnt.most_common())[:,1]\n",
    "cnt_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "if full_execute:\n",
    "    stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_cnt=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if full_execute:\n",
    "    idx_cnt += 50\n",
    "    cnt_df[cnt_df['tag'].str.startswith('N')][idx_cnt:idx_cnt+50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 수동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cnt_idx = 1300, cnt < 66\n",
    "'''\n",
    "ridx = [4, 6, 10, 15, 25, 41, 45, 60, 61, 64, 78, 90, 91, 96, 97, 102, 107, 109, 140, 145, 160, 161, 162, 186, 188,\n",
    "205, 221, 234, 249, 253, 260, 268, 271, 272, 280, 281, 282, 284, 292, 302, 304, 314, 316, 320, 324, 328, 356,\n",
    "362, 379, 381, 399, 415, 416, 430, 434, 453, 462, 465, 466, 469, 479, 487, 495, 496, 498, 503, 508, 514, 516,\n",
    "521, 525, 528, 551, 552, 555, 563, 569, 573, 576, 577, 583, 585, 599, 600, 603, 608, 610, 612, 618, 629, 631,\n",
    "650, 655, 671, 674, 683, 690, 693, 700, 701, 714, 724, 728, 729, 732, 733, 739, 742, 745, 748, 750, 754, 756,\n",
    "759, 764, 771, 778, 785, 788, 789, 795, 803, 826, 830, 843, 859, 866, 876, 881, 883, 901, 913, 931, 934, 939,\n",
    "947, 956, 961, 965, 967, 972, 973, 978, 990, 1010, 1027, 1034, 1045, 1046, 1053, 1058, 1063, 1078, 1088, 1089, 1109, 1110, 1112, 1116, 1120, 1137, 1141, 1145, 1147, 1155, 1157, 1158, 1160, 1168, 1179, 1187, 1207,\n",
    "1210, 1211, 1214, 1223, 1225, 1231, 1234, 1238, 1241, 1256, 1264, 1267, 1269, 1278, 1283, 1286, 1290, 1293,\n",
    "1301, 1308, 1316, 1319, 1322, 1341, 1352, 1354, 1355, 1370, 1375, 1390, 1391, 1402, 1415, 1417, 1418, 1421,\n",
    "1423, 1430, 1432, 1437, 1445, 1456, 1457, 1458, 1459, 1481, 1492, 1497, 1500, 1501, 1504, 1505, 1509, 1517,\n",
    "1518, 1523, 1533, 1535, 1538, 1541, 1560, 1565, 1575, 1576, 1591, 1595, 1596, 1601, 1607, 1608, 1611, 1617,\n",
    "1619, 1624, 1634, 1637, 1638, 1642, 1652, 1657, 1663, 1664, 1689, 1699, 1701, 1706, 1721]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 수동 이후 부분 중 명사, 길이 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "idx > 1720, tag == N, word len = 1, cnt < 66,\n",
    "'''\n",
    "stops_idx = cnt_df[(cnt_df['tag'].str.startswith('N')) & (cnt_df['cnt'] < 66) & (cnt_df['word'].agg(len) == 1)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 1720,  1723,  1724,  1757,  1780,  1783,  1809,  1850,  1859,\n",
      "             1875,\n",
      "            ...\n",
      "            29168, 29207, 29693, 29748, 30559, 30952, 31000, 31076, 31142,\n",
      "            31787],\n",
      "           dtype='int64', length=579)\n",
      "Int64Index([   4,    6,   10,   15,   25,   41,   45,   60,   61,   64,\n",
      "            ...\n",
      "            1642, 1652, 1657, 1663, 1664, 1689, 1699, 1701, 1706, 1721],\n",
      "           dtype='int64', length=259)\n"
     ]
    }
   ],
   "source": [
    "print(cnt_df.loc[stops_idx][['word','tag']].index)\n",
    "print(cnt_df.loc[ridx,][['word','tag']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stops = np.concatenate((cnt_df.loc[stops_idx][['word','tag']].values, cnt_df.loc[ridx,][['word','tag']].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불용어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./stopwords/1.txt',encoding='utf-8') as f:\n",
    "    stops1 = f.readlines()\n",
    "with open('./stopwords/2.txt',encoding='utf-8') as f:\n",
    "    stops2 = f.readlines()\n",
    "with open('./stopwords/3.txt',encoding='utf-8') as f:\n",
    "    stops3 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops1 = list(map(lambda x: x.replace('\\n',''),stops1))\n",
    "stops2 = list(map(lambda x: x.replace('\\n',''),stops2))\n",
    "stops3 = list(map(lambda x: x.replace('\\n',''),stops3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(set(stops1) & set(stops2) & set(stops3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if full_execute:\n",
    "    result_kkma = []\n",
    "    for plot in tqdm(plots):\n",
    "        words = []\n",
    "        for word,tag in kkma.pos(plot):\n",
    "            if tag in ['NNG', 'NNP', 'VV']:\n",
    "                words.append(word)\n",
    "        words = (' '.join(words)).strip()\n",
    "        result_kkma.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_execute:\n",
    "    with open('naver_plot_kkma.nlp','w',encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(result_kkma))\n",
    "\n",
    "    w2v_kkma = word2vec.LineSentence('./model/naver_plot_kkma.nlp')\n",
    "    model_kkma = word2vec.Word2Vec(w2v_kkma, size=200, window=5, hs=1, min_count=2, sg=1)\n",
    "    model_kkma.save('./model/naver_plot_kkma.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_kmr = []\n",
    "for plot in tqdm(df['plot']):\n",
    "    words = []\n",
    "    for word,tag in komoran.pos(plot):\n",
    "        #if tag in ['NNG', 'NNP', 'VV']:\n",
    "        if tag in ['NNG', 'NNP']:\n",
    "            words.append(word)\n",
    "    words = (' '.join(words)).strip()\n",
    "    result_kmr.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model/naver_plot_kmr.nlp','w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(result_kmr))\n",
    "\n",
    "w2v_kmr = word2vec.LineSentence('./model/naver_plot_kmr.nlp')\n",
    "model_kmr = word2vec.Word2Vec(w2v_kmr, size=200, window=5, hs=1, min_count=10, sg=1)\n",
    "model_kmr.save('./model/naver_plot_kmr_min10_N_only.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load & test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_execute:\n",
    "    model_kkma = word2vec.Word2Vec.load('./model/naver_plot_kkma.model')\n",
    "model_kmr = word2vec.Word2Vec.load('./model/naver_plot_kmr_min10_N_only.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if full_execute:\n",
    "    word = '레이싱'\n",
    "    print('most similar words to',word,'in word2vec')\n",
    "    print('Kkma\\t\\t\\t\\tKomoran')\n",
    "    for (w1,t1),(w2,t2) in zip(model_kkma.wv.most_similar(word,topn=20), model_kmr.wv.most_similar(word,topn=20)):\n",
    "        print(\"%-10s\\t%.4f\\t\\t%-10s\\t%.4f\"%(w1,t1,w2,t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#출처 : https://bab2min.tistory.com/570\n",
    "class RawTaggerReader:\n",
    "    def __init__(self, plot, tagger = None):\n",
    "        if tagger:\n",
    "            self.tagger = tagger\n",
    "        else :\n",
    "            from konlpy.tag import Komoran\n",
    "            self.tagger = Komoran()\n",
    "        self.plot = plot\n",
    "        self.rgxSplitter = re.compile('([.!?:](?:[\"\\']|(?![0-9])))')\n",
    " \n",
    "    def __iter__(self):\n",
    "        ch = self.rgxSplitter.split(self.plot)\n",
    "        if len(ch) == 1: ch.append('.')\n",
    "        for s in map(lambda a,b:a+b, ch[::2], ch[1::2]):\n",
    "            if not s: continue\n",
    "            yield self.tagger.pos(s)\n",
    "\n",
    "class TextRank:\n",
    "    def __init__(self, **kargs):\n",
    "        self.graph = None\n",
    "        self.window = kargs.get('window', 5)\n",
    "        self.coef = kargs.get('coef', 1.0)\n",
    "        self.threshold = kargs.get('threshold', 0.005)\n",
    "        self.dictCount = {}\n",
    "        self.dictBiCount = {}\n",
    "        self.dictNear = {}\n",
    "        self.nTotal = 0\n",
    "\n",
    "    def load(self, sentenceIter, wordFilter = None):\n",
    "        def insertPair(a, b):\n",
    "            if a > b: a, b = b, a\n",
    "            elif a == b: return\n",
    "            self.dictBiCount[a, b] = self.dictBiCount.get((a, b), 0) + 1\n",
    " \n",
    "        def insertNearPair(a, b):\n",
    "            self.dictNear[a, b] = self.dictNear.get((a, b), 0) + 1\n",
    " \n",
    "        for sent in sentenceIter:\n",
    "            for i, word in enumerate(sent):\n",
    "                if wordFilter and not wordFilter(word): continue\n",
    "                self.dictCount[word] = self.dictCount.get(word, 0) + 1\n",
    "                self.nTotal += 1\n",
    "                if i - 1 >= 0 and (not wordFilter or wordFilter(sent[i-1])): insertNearPair(sent[i-1], word)\n",
    "                if i + 1 < len(sent) and (not wordFilter or wordFilter(sent[i+1])): insertNearPair(word, sent[i+1])\n",
    "                for j in range(i+1, min(i+self.window+1, len(sent))):\n",
    "                    if wordFilter and not wordFilter(sent[j]): continue\n",
    "                    if sent[j] != word: insertPair(word, sent[j])\n",
    "\n",
    "    def getPMI(self, a, b):\n",
    "        import math\n",
    "        co = self.dictNear.get((a, b), 0)\n",
    "        if not co: return None\n",
    "        return math.log(float(co) * self.nTotal / self.dictCount[a] / self.dictCount[b])\n",
    " \n",
    "    def getI(self, a):\n",
    "        import math\n",
    "        if a not in self.dictCount: return None\n",
    "        return math.log(self.nTotal / self.dictCount[a])\n",
    " \n",
    "    def build(self):\n",
    "        self.graph = networkx.Graph()\n",
    "        self.graph.add_nodes_from(self.dictCount.keys())\n",
    "        for (a, b), n in self.dictBiCount.items():\n",
    "            self.graph.add_edge(a, b, weight=n*self.coef + (1-self.coef))\n",
    " \n",
    "    def rank(self):\n",
    "        return networkx.pagerank(self.graph, weight='weight')\n",
    " \n",
    "    def extract(self, ratio = 0.1):\n",
    "        ranks = self.rank()\n",
    "\n",
    "        if int(len(ranks) * ratio) > 10:\n",
    "            cand = sorted(ranks, key=ranks.get, reverse=True)[:int(len(ranks) * ratio)]\n",
    "        else:\n",
    "            cand = sorted(ranks, key=ranks.get, reverse=True)[:10]\n",
    "        pairness = {}\n",
    "        startOf = {}\n",
    "        tuples = {}\n",
    "\n",
    "        for k in cand:\n",
    "            tuples[(k,)] = self.getI(k) * ranks[k]\n",
    "            for l in cand:\n",
    "                if k == l: continue\n",
    "                pmi = self.getPMI(k, l)\n",
    "                if pmi: pairness[k, l] = pmi\n",
    " \n",
    "        for (k, l) in sorted(pairness, key=pairness.get, reverse=True):\n",
    "            if k not in startOf: startOf[k] = (k, l)\n",
    " \n",
    "        for (k, l), v in pairness.items():\n",
    "            pmis = v\n",
    "            rs = ranks[k] * ranks[l]\n",
    "            path = (k, l)\n",
    "            tuples[path] = pmis / (len(path) - 1) * rs ** (1 / len(path)) * len(path)\n",
    "            last = l\n",
    "            while last in startOf and len(path) < 7:\n",
    "                if last in path: break\n",
    "                pmis += pairness[startOf[last]]\n",
    "                last = startOf[last][1]\n",
    "                rs *= ranks[last]\n",
    "                path += (last,)\n",
    "                tuples[path] = pmis / (len(path) - 1) * rs ** (1 / len(path)) * len(path)\n",
    "\n",
    "        used = set()\n",
    "        both = {}\n",
    "        for k in sorted(tuples, key=tuples.get, reverse=True):\n",
    "            if len(k) == 1:\n",
    "                if used.intersection(set(k)): continue\n",
    "                both[k] = tuples[k]\n",
    "                for w in k:\n",
    "                    used.add(w)\n",
    "        \n",
    "        return both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4cf7828976b40919e41d5405e5df63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10255), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /10255 ['마지막', '발명품', '유령']\n",
      "100 /10255 ['말', '기사', '라디오', '장난', '카페', '기적', '시작', '가에', '화가', '사연']\n",
      "200 /10255 ['신비', '요정', '세계', '위험', '마법', '기억', '마왕', '모험', '시작', '사실']\n",
      "300 /10255 ['찰스', '탐정', '손녀', '소피아', '사립', '도착', '구성원', '살인', '동기', '가족']\n",
      "400 /10255 ['전문가', '괴물', '첨단', '특수', '훈련', '기지', '전투', '파일럿', '로스', '박사']\n",
      "500 /10255 ['마음', '작품', '목소리', '세대', '기록', '할리우드', '이야기', '블록버스터']\n",
      "600 /10255 ['진입', '자리', '남자', '위협', '비밀', '출장', '최악', '일상', '컴백', '비행']\n",
      "700 /10255 ['폭력', '소녀', '이사', '첫사랑', '추억', '위험', '선택', '경찰관', '아버지', '첫눈']\n",
      "800 /10255 ['답장', '과거', '가게', '뮤지', '도둑', '아츠', '인연', '연결', '이름', '편지']\n",
      "900 /10255 ['프리', '작업', '충격', '사이', '의구심', '인터뷰', '천국', '필리핀', '시나리오', '비밀']\n",
      "1000 /10255 ['아빠', '결혼', '선배', '아가씨', '생일날', '안하무인', '사랑', '사실', '첫사랑', '짝사랑']\n",
      "1100 /10255 ['임무', '가장', '행복', '무기', '거래', '가석방', '출소', '성공', '증권', '사고']\n",
      "1200 /10255 ['미래', '인공지능', '로봇', '강아지', '특징', '간직', '생사', '모험', '시작', '발견']\n",
      "1300 /10255 ['이모', '마음', '딸', '입사', '시험', '유미', '준비', '어머니', '전화', '집']\n",
      "1400 /10255 ['청년', '해머', '햇살', '가족', '별장', '아버지', '소년', '스물', '보조', '연구원']\n",
      "1500 /10255 ['해외', '소녀', '도쿄', '학교', '최고', '인기', '운명', '남자', '선생님', '남']\n",
      "1600 /10255 ['조선인', '주먹', '소속', '시작', '인사', '구출', '작전', '폭격', '일제', '일본']\n",
      "1700 /10255 ['카이', '남매', '전설', '금지', '동굴', '로렌', '마법', '대결', '불의', '마왕']\n",
      "1800 /10255 ['닌자', '로이드', '시티', '악당', '고양이', '학생', '방', '실력', '발휘', '돈']\n",
      "1900 /10255 ['인어', '위협', '자연', '지역', '극비리', '계획', '인간', '생존', '돈', '부동산']\n",
      "2000 /10255 ['여자', '판타지', '섹스', '남자', '침대', '섹스', '건물', '이사', '경험', '실현']\n",
      "2100 /10255 ['어른', '운명', '우정은', '시작', '청춘', '이야기', '스물', '이별', '첫사랑', '사랑']\n",
      "2200 /10255 ['한밤', '당첨', '미셸', '관객', '소재', '공포', '대상', '게임', '극장', '투어']\n",
      "2300 /10255 ['장군', '감옥', '영감', '장', '돈', '마지막', '병', '살인', '천사', '시진']\n",
      "2400 /10255 ['강호', '무림', '청나라', '잡기', '사부', '조정', '관료', '대회', '핑계', '잔혹']\n",
      "2500 /10255 ['가정', '사이', '남편', '현장', '레오나르도', '잠복', '근무', '경찰', '출장', '사랑']\n",
      "2600 /10255 ['공룡', '탐험', '구성', '세계', '한반도', '발견', '박사', '미스터리', '탐험대', '화석']\n",
      "2700 /10255 ['남편', '섹스', '연결', '해달', '기호', '결혼', '역할', '몰입', '통화', '생활']\n",
      "2800 /10255 ['돈', '사건', '동료', '카지노', '보스', '숨', '추격', '남자', '마피아', '딸']\n",
      "2900 /10255 ['병원', '세상', '고양이', '올해', '배달부', '하루', '말', '방법', '묘안', '추억']\n",
      "3000 /10255 ['동석', '야동', '방학', '여자', '삼총사', '미애', '관심', '거지', '성은', '학원']\n",
      "3100 /10255 ['바람', '세상', '꿈', '조선', '시대', '최고', '용주', '생각', '자유', '여자']\n",
      "3200 /10255 ['처음', '헌신', '백화점', '손님', '이혼', '소송', '혼란', '통제', '서로', '확신']\n",
      "3300 /10255 ['아내', '클레어', '권력', '수단', '방법', '냉혈', '정치인', '자비', '워싱턴', '하원']\n",
      "3400 /10255 ['스포츠', '야구', '사회', '생애', '이름', '소년', '국민', '한국', '기억', '관중']\n",
      "3500 /10255 ['영화', '현장', '창작', '고통', '제작자', '중단', '상업', '요구', '감독', '촬영']\n",
      "3600 /10255 ['다비드', '폭력배', '가방', '몸매', '국가대표', '동원', '돈', '여자', '기획사', '이름']\n",
      "3700 /10255 ['사건', '살해', '변호사', '소송', '용의자', '확률', '에이스', '증거', '성공', '시작']\n",
      "3800 /10255 ['사고뭉치', '불량', '학생', '육식', '동물', '먹이']\n",
      "3900 /10255 ['사업', '시험', '대학', '위기', '교수', '패스', '제안', '아이템', '기획', '성공']\n",
      "4000 /10255 ['친구', '모리스', '타이거', '펭귄', '지도', '해적', '수지', '신비', '바다', '아빠']\n",
      "4100 /10255 ['세계로', '천재', '지구', '종말', '첨단', '과학', '기술', '선택', '자만', '세상']\n",
      "4200 /10255 ['할배', '청춘']\n",
      "4300 /10255 ['바나나', '섬', '반', '바나나', '추위', '산', '중앙', '남쪽', '여왕', '힘']\n",
      "4400 /10255 ['살인', '전직', '목격', '현장', '사건', '수사', '발생', '출소', '차례', '혐의']\n",
      "4500 /10255 ['엘프', '여정', '드래곤', '나이트', '납치', '로코', '왕국', '영웅', '위험', '아들']\n",
      "4600 /10255 ['선재', '음악', '사랑', '예술', '재단', '교감', '천재', '피아니스트', '멜로', '드라마']\n",
      "4700 /10255 ['꼬마', '소녀', '호시', '미야', '꿈', '세계', '정복', '망상', '지도자', '영광']\n",
      "4800 /10255 ['보험', '회사', '협상', '경관', '금', '잡기', '함정', '마련', '미술품', '거액']\n",
      "4900 /10255 ['부모', '젤리', '틈', '모범생', '경찰', '추적', '풋볼', '팀', '주장', '시작']\n",
      "5000 /10255 ['요정', '질투', '사랑', '충격', '목숨', '포로', '모습', '혼신', '힘', '미모']\n",
      "5100 /10255 ['사랑', '폭력', '작품', '아트', '다큐멘터리', '스크린', '전쟁', '공포', '극복', '세계']\n",
      "5200 /10255 ['토론', '정체성', '민족', '이유', '사회', '문제', '주제', '결혼', '가정', '조선족']\n",
      "5300 /10255 ['힘', '비행기', '행방불명', '비밀', '간직', '수수께끼', '어른', '섬', '신비', '스파이']\n",
      "5400 /10255 ['목숨', '사용', '반', '자와', '세상', '두지', '결심', '먼지', '군가', '어른']\n",
      "5500 /10255 ['사랑', '대한민국', '최고', '욕망', '향연', '녀', '순정', '낮', '여배우', '며느리']\n",
      "5600 /10255 ['가족', '청춘', '사랑', '이야기', '인생', '황혼', '성장', '드라마', '좌충우돌', '로맨스']\n",
      "5700 /10255 ['행복', '공세', '치명', '호화', '교양', '결혼', '저택', '사교계', '이성', '외모']\n",
      "5800 /10255 ['작전', '거래', '테러리스트', '대상', '결정', '슬픔', '단서', '마지막', '마야', '최대']\n",
      "5900 /10255 ['경악', '폭파', '생존자', '시작', '테러', '발생', '지하철', '부상', '구조', '폭발물']\n",
      "6000 /10255 ['신비', '악당', '고릴라', '레드', '팬더', '아저씨', '피해', '기적', '마녀', '친구']\n",
      "6100 /10255 ['산타', '사랑', '동생', '기대', '크리스마스', '점령', '공장', '해피', '사수', '사슴', '하늘']\n",
      "6200 /10255 ['딸', '마들렌', '이름', '죄', '이유', '전과자', '리드', '신부', '손길', '구원']\n",
      "6300 /10255 ['친구', '영웅', '박사', '경기', '진행', '지구', '팀', '로봇', '전투', '우주']\n",
      "6400 /10255 ['성공', '회사', '최고', '디자이너', '하룻밤', '좌충우돌', '로맨틱', '구두', '신입사원', '실수']\n",
      "6500 /10255 ['남녀', '이야기', '사랑', '욕망']\n",
      "6600 /10255 ['비밀', '의심', '혼란', '방법', '돈', '라온', '사이', '용서', '여자', '강도']\n",
      "6700 /10255 ['추구', '경험', '해체', '가족', '욕망', '소유', '가난', '고통', '여성', '집착']\n",
      "6800 /10255 ['억척', '삶', '개척', '아줌마', '이야기', '이혼']\n",
      "6900 /10255 ['결혼', '공개', '지옥', '알코올', '중독자', '사무실', '눈물', '복수', '난리', '상사']\n",
      "7000 /10255 ['야구', '모자', '핏자국', '방', '전화', '전기', '소리', '택시', '기사', '말', '휴게']\n",
      "7100 /10255 ['해리', '마법', '마지막', '볼드모트', '비밀', '생물', '호그와트', '위기', '힘', '포스']\n",
      "7200 /10255 ['경관', '강압', '구조', '유일한', '현지', '동굴', '기억상실', '공포', '감지', '조각']\n",
      "7300 /10255 ['결합', '결말', '성', '과학자', '실험', '금기', '의학', '강행', '급속도', '성인']\n",
      "7400 /10255 ['유괴', '믿음', '추격', '시작', '기도', '한번', '기회', '사건', '발생', '딸']\n",
      "7500 /10255 ['아르세우스', '힘', '마을', '모스', '옛날', '지우', '일행', '생명', '운석', '분노']\n",
      "7600 /10255 ['배달', '보경', '거래', '김치', '일본', '아저씨', '사업가', '여자', '납치', '불안']\n",
      "7700 /10255 ['미술', '속셈', '복원', '한국', '공장', '관심', '살인', '미술', '그림', '복제']\n",
      "7800 /10255 ['애증', '이혼', '복수', '사랑', '남성', '과거', '능력', '이야기']\n",
      "7900 /10255 ['남자', '폭력', '암울', '판매', '제거', '고소', '술집', '총기', '남자친구', '라일']\n",
      "8000 /10255 ['사건', '소동', '시트콤', '주인공']\n",
      "8100 /10255 ['감독', '알프레드', '뮤지컬', '파커', '주연', '제작', '웨스턴', '주연', '코믹', '자인', '록키', '마지막']\n",
      "8200 /10255 ['여자', '과거', '프랑스', '고향', '적응', '파리', '낯선', '도시', '남자친구', '들로']\n",
      "8300 /10255 ['이별', '생각', '화가', '이해', '시작', '시카고', '갤러리', '애정', '공세', '친구']\n",
      "8400 /10255 ['겸비', '테크닉', '목적', '연애', '쇼핑', '리스트', '시대', '최고', '미모', '작업']\n",
      "8500 /10255 ['유일한', '최고', '향수', '삶', '매혹', '프랑스', '생선', '향기', '소유', '파리']\n",
      "8600 /10255 ['시작', '커플', '가방', '미나', '사랑', '데이트', '그림', '표현', '장난', '연애']\n",
      "8700 /10255 ['자극', '역할', '명자', '대중', '업체', '말투', '인줄', '단체', '애교', '드라마', '비상', '시청자', '설정', '춤', '사채', '옷', '성과', '발생', '만원', '말', '모임', '마음']\n",
      "8800 /10255 ['에코', '애니메이션', '유코', '타루', '청년', '도시', '여름', '휴가', '만화', '휴가']\n",
      "8900 /10255 ['대원', '일기', '도달', '불능', '통신', '장비', '세계', '탐험', '영국', '남극']\n",
      "9000 /10255 ['대부', '상어', '바다', '리노', '오스카', '아들', '돈', '세계', '사건', '모면', '정면', '위기']\n",
      "9100 /10255 ['시작', '피해자', '영향', '이용', '잡지', '방', '조사', '살인', '거리', '마크']\n",
      "9200 /10255 ['드라마', '갈등', '인생', '드라마', '사랑', '엄마', '억지', '재미', '치유', '방송', '아픔']\n",
      "9300 /10255 ['이혼', '아일랜드', '밤', '법정', '직감', '낭만', '소송', '신성', '세간', '이목']\n",
      "9400 /10255 ['청년', '실험', '성향', '우려', '감독', '가족', '요구', '화목', '리얼', '구로']\n",
      "9500 /10255 ['경찰', '마약', '활동', '잠입', '제보', '나크', '총격', '사건', '관련', '살해']\n",
      "9600 /10255 ['악령', '정전', '불빛', '아이들', '저주', '사실', '존재', '마을', '어둠', '밤', '얼굴']\n",
      "9700 /10255 ['중간', '서울', '도끼', '보스', '친구', '반대', '패거리', '갱스터', '생활', '강남']\n",
      "9800 /10255 ['외출', '스텔라', '여동생', '물고기', '약', '숙모', '상어', '박사', '해독제', '바다']\n",
      "9900 /10255 ['베이징', '자전거', '대신', '고등학교', '진학', '손님', '자전거', '불만', '소년', '실버', '순수']\n",
      "10000 /10255 ['엄마', '버스', '봉투', '실연', '시즈', '남자', '호기심', '군가', '사진', '기대']\n",
      "10100 /10255 ['술', '첩보', '사설', '폭파', '회사', '임무', '납치', '실력', '탐정', '국가', '변장', '세계', '사건', '사무소', '규모', '최대', '출신', '미인', '근무']\n",
      "10200 /10255 ['갱', '경찰', '보스', '눈', '제프', '잠입', '미라', '애인', '갱스터', '조직원', '생활']\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for idx in tqdm(df.index):\n",
    "    keywords = []\n",
    "    tr = TextRank(window=5, coef=1)\n",
    "    stopword = set([('있', 'VV'), ('하', 'VV'), ('되', 'VV'), ('없', 'VV'),\n",
    "                   ('위하', 'VV')]).union(set(map(lambda x: tuple(x),stops)))\n",
    "    tr.load(RawTaggerReader(df.loc[idx,'plot']),\n",
    "            lambda w:w not in stopword and w[0] not in stopwords and\n",
    "            w[0] in model_kmr.wv.vocab and (w[1] in ('NNG', 'NNP')))\n",
    "            #and w[0] in model_kmr.wv.vocab and (w[1] in ('NNG', 'NNP', 'VV')))\n",
    "    tr.build()\n",
    "    kw = tr.extract(0.2)\n",
    "    for k in sorted(kw, key=kw.get, reverse=True):\n",
    "        keywords.append(k[0][0])\n",
    "        #print(\"%s\\t%g\" % (k, kw[k]))\n",
    "    if idx %100 == 0:\n",
    "        print(idx,'/10255',keywords)\n",
    "    results.append(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_df = pd.DataFrame([(idx,result) for idx,result in zip(df.index,results)],columns=['idx','keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_df.to_csv('./movie_keywords_1231.csv',index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "del keyword_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_df = pd.read_csv('./movie_keywords_1231.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['마지막', '발명품', '유령']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['선상', '몸', '성욕', '사랑', '남자', '운명', '남편', '여인']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['은행', '기술자', '직감', '용납', '멤버', '비상', '설계자', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['성사', '집으로', '집', '운영', '공동', '스마트폰', '아마존', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['디지털', '권리', '통제', '교육', '유산', '수도', '세상', '신...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>['총상', '탈출', '유일한', '노르웨이', '저항', '작전', '발각', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>['엄마', '대신', '도시락', '원망', '그리움', '형', '준비', '아...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>['세상', '독립', '소녀', '시작', '이름', '기억', '기록']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>['현실', '가상', '세계', '살인', '테러', '조직', '미래', '유럽...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>['사고', '목숨', '극한', '고대', '마야', '예기', '피해', '숨바...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                           keywords\n",
       "0    0                               ['마지막', '발명품', '유령']\n",
       "1    1    ['선상', '몸', '성욕', '사랑', '남자', '운명', '남편', '여인']\n",
       "2    2  ['은행', '기술자', '직감', '용납', '멤버', '비상', '설계자', '...\n",
       "3    3  ['성사', '집으로', '집', '운영', '공동', '스마트폰', '아마존', ...\n",
       "4    4  ['디지털', '권리', '통제', '교육', '유산', '수도', '세상', '신...\n",
       "5    5  ['총상', '탈출', '유일한', '노르웨이', '저항', '작전', '발각', ...\n",
       "6    6  ['엄마', '대신', '도시락', '원망', '그리움', '형', '준비', '아...\n",
       "7    7         ['세상', '독립', '소녀', '시작', '이름', '기억', '기록']\n",
       "8    8  ['현실', '가상', '세계', '살인', '테러', '조직', '미래', '유럽...\n",
       "9    9  ['사고', '목숨', '극한', '고대', '마야', '예기', '피해', '숨바..."
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(df,keyword_df,left_on=df.index,right_on=keyword_df.idx,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.drop(columns=['key_0', 'idx'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('./merged.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
