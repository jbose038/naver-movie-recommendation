{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클러스터링 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition.truncated_svd import TruncatedSVD\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class movie_recommendation_cluster:\n",
    "    def __init__(self, **kargs):\n",
    "        self.topn = kargs.get('topn', 10)\n",
    "        self.df = kargs.get('data', pd.read_csv('./dataset/movies04293.csv'))\n",
    "        self.a, self.b, self.c = kargs.get('a',0.8), kargs.get('b',0.1), kargs.get('c',0.1)\n",
    "        self.n_clusters = kargs.get('n_clusters',30)# kmeans\n",
    "        self.n_components = kargs.get('n_components', 500)# svd\n",
    "        self.vote_thres = kargs.get('vote_thres',100)# vote_count\n",
    "        self.verbose = kargs.get('verbose', 1)\n",
    "        self.re_cluster = kargs.get('re_cluster', 1)# kmeans\n",
    "        self.batch_size = kargs.get('batch_size', 2000)\n",
    "        self.max_iter = kargs.get('max_iter', 500)\n",
    "        \n",
    "        self.cvec = CountVectorizer(min_df=0, ngram_range=(1,2))\n",
    "        self.stops = []\n",
    "        with open('./stopwords/total_stopwords', encoding='utf-8') as f:\n",
    "            self.stops.append(f.readline()[:-2])\n",
    "        \n",
    "        if self.verbose == 1:\n",
    "            print('-'*35)\n",
    "            print('# Parameters')\n",
    "            print('      a, b, c        : {0}, {1}, {2}'.format(self.a, self.b, self.c))\n",
    "            print('vote count threshold :', self.vote_thres)\n",
    "            print(\"n_components of SVD  :\", self.n_components)\n",
    "            print(\"n_clusters of KMeans :\", self.n_clusters)\n",
    "            print('batch_size of Kmeans :', self.batch_size)\n",
    "            print('max_iter of Kmeans   :', self.max_iter)\n",
    "            print('weighted_sum = dist_scaled*{0}(a) + genre_scaled*{1}(b) + wvote_scaled*{2}(c)'.format(self.a, self.b, self.c))\n",
    "            print('-'*35)\n",
    "    \n",
    "    def search_title(self, title_name):\n",
    "        return self.df[self.df['title'].str.contains(title_name)].title\n",
    "    \n",
    "    def genre_sim_sorted(self, title_idx):\n",
    "        genre_literal = self.df['genre'].apply(lambda x: x.replace('|',' '))\n",
    "        genre = self.cvec.fit_transform(genre_literal)\n",
    "        genre_sim = cosine_similarity(genre,genre)\n",
    "        \n",
    "        return np.array([(idx,sim) for idx,sim in enumerate(genre_sim[title_idx])])\n",
    "    \n",
    "    def raw_to_tfidf(self, data_preprocess):\n",
    "        tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1,3),stop_words=self.stops,\n",
    "                                     min_df=3, max_df=0.95, max_features=10000)\n",
    "        return tfidf.fit_transform(data_preprocess)\n",
    "    def tfidf_to_svd(self, data_tfidf):\n",
    "        svd = TruncatedSVD(n_components=self.n_components, n_iter=10)\n",
    "        return svd.fit_transform(data_tfidf)\n",
    "    \n",
    "    def similar_cluster_movies(self, title_idx):\n",
    "        do_cluster, loop_cnt = True, 0\n",
    "        \n",
    "        # data preprocessing\n",
    "        data_tfidf = self.raw_to_tfidf(list(map(str, self.df['plot_preprocessed_kkma'].values)))\n",
    "        data_svd = self.tfidf_to_svd(data_tfidf)\n",
    "        \n",
    "        # K-means clustering\n",
    "        print('Clustering...')\n",
    "        while do_cluster:\n",
    "            kmeans = MiniBatchKMeans(n_clusters=self.n_clusters, batch_size=self.batch_size,\n",
    "                                     max_iter=self.max_iter, verbose=0 ,n_init=3)\n",
    "\n",
    "            vote_over_thres_idx = self.df[self.df['vote_count'] > self.vote_thres].index\n",
    "            data_svd_idx = np.array([(idx,val) for idx,val in zip(self.df.index,data_svd)])\n",
    "            data_svd_to_km = [val for idx,val in data_svd_idx if idx in vote_over_thres_idx]\n",
    "            data_svd_dict = dict([(idx,val) for idx,val in filter(lambda x: x[0] in vote_over_thres_idx, data_svd_idx)])\n",
    "            \n",
    "            # (optional)avoid biggest cluster\n",
    "            km = kmeans.fit(data_svd_to_km)\n",
    "            km_dict = dict([(df_idx,label_) for df_idx,label_ in zip(vote_over_thres_idx,km.labels_)])\n",
    "            km_cluster = list(filter(lambda x: km_dict.get(x) == km_dict.get(title_idx), km_dict.keys()))\n",
    "\n",
    "            clusters = [0]*self.n_clusters\n",
    "            for label_ in km.labels_:\n",
    "                clusters[label_] += 1\n",
    "\n",
    "            clusters_idx = np.array(clusters).argsort()\n",
    "            bad_clusters = clusters_idx[-3:]\n",
    "            \n",
    "            if self.re_cluster:            \n",
    "                if km_dict.get(title_idx) not in bad_clusters:\n",
    "                    do_cluster=False\n",
    "                elif loop_cnt >= 20:\n",
    "                    print('Loop count exceeded')\n",
    "                    do_cluster=False\n",
    "                else:\n",
    "                    del kmeans\n",
    "                    loop_cnt += 1\n",
    "                    print('Re-clustering...(%d)'%(loop_cnt))\n",
    "                    \n",
    "            else:\n",
    "                do_cluster = False\n",
    "\n",
    "        if self.verbose == 1:\n",
    "            print('-'*35)\n",
    "            print('# K-means clustering distribution')\n",
    "            for i,size in enumerate(clusters):\n",
    "                postfix = '<==' if i == km_dict.get(title_idx) else ''\n",
    "                print('cluster #%3d : %4d items %s'%(i,size,postfix))\n",
    "            print('-'*35)\n",
    "\n",
    "        closest = []\n",
    "        for i in km_cluster:\n",
    "            if i != title_idx:\n",
    "                closest.append((i,euclidean(data_svd_dict.get(title_idx), data_svd_dict.get(i))))\n",
    "\n",
    "        return np.array(closest), self.df.loc[np.array(sorted(closest, key=lambda x: x[1]))[:,0]]\n",
    "\n",
    "    def result_by_weights(self, dataf):\n",
    "        dataf['weighted_sum'] = dataf['dist_scaled']*self.a + dataf['genre_scaled']*self.b + dataf['wvote_scaled']*self.c\n",
    "        \n",
    "        return dataf.sort_values('weighted_sum', ascending=False)\n",
    "\n",
    "            \n",
    "    def getMovies(self, title):\n",
    "        # no title result\n",
    "        try: title_idx = self.df[self.df['title']== title].index.values[0]\n",
    "        except:\n",
    "            raise ValueError('There is no such title name. Search with \"search_title\" function')\n",
    "        \n",
    "        # get movies in same cluster\n",
    "        dist, result = self.similar_cluster_movies(title_idx)\n",
    "        \n",
    "        # merge with distance\n",
    "        result = pd.merge(result, pd.Series(dist[:,1], name='dist'), left_on=result.index, right_on=dist[:,0])\n",
    "        result.rename(columns={'key_0':'idx'}, inplace=True)\n",
    "        \n",
    "        # IMDB's weighted_vote\n",
    "        def weighted_vote_average(record):\n",
    "            v, r = record['vote_count'], record['rating']\n",
    "            return (v/(v+m))*r + (m/(m+v))*c\n",
    "        c = result['rating'].mean()\n",
    "        m = result['vote_count'].quantile(.6)\n",
    "        result['weighted_vote'] = result.apply(weighted_vote_average,axis=1)\n",
    "        \n",
    "        # merge with genre\n",
    "        genre_sim = self.genre_sim_sorted(title_idx)\n",
    "        result_with_genre = pd.merge(result, pd.Series(genre_sim[:,1], name='genre_sim'), left_on=result.idx, right_on=genre_sim[:,0],)\n",
    "        \n",
    "        # minmax scale\n",
    "        result_with_genre['wvote_scaled'] = MinMaxScaler().fit_transform(result_with_genre['weighted_vote'].values.reshape(-1,1))\n",
    "        result_with_genre['genre_scaled'] = MinMaxScaler().fit_transform(result_with_genre['genre_sim'].values.reshape(-1,1))\n",
    "        result_with_genre['dist_scaled'] = MinMaxScaler().fit_transform(result_with_genre['dist'].max() - result_with_genre['dist'].values.reshape(-1,1))\n",
    "        \n",
    "        # (optional)remove data with 0 genre score\n",
    "        no_genre_score_idx = result_with_genre[result_with_genre['genre_sim'] == 0].index\n",
    "        result_with_genre.drop(no_genre_score_idx, inplace=True)\n",
    "        \n",
    "        result_with_genre = self.result_by_weights(result_with_genre)\n",
    "        return result_with_genre.head(self.topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "# Parameters\n",
      "      a, b, c        : 0.8, 0.1, 0.1\n",
      "vote count threshold : 100\n",
      "n_components of SVD  : 500\n",
      "n_clusters of KMeans : 30\n",
      "batch_size of Kmeans : 2000\n",
      "max_iter of Kmeans   : 500\n",
      "weighted_sum = dist_scaled*0.8(a) + genre_scaled*0.1(b) + wvote_scaled*0.1(c)\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "recom = movie_recommendation_cluster(re_cluster=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering...\n",
      "Re-clustering...(1)\n",
      "Re-clustering...(2)\n",
      "Re-clustering...(3)\n",
      "-----------------------------------\n",
      "# K-means clustering distribution\n",
      "cluster #  0 :  122 items \n",
      "cluster #  1 :   80 items \n",
      "cluster #  2 :   53 items \n",
      "cluster #  3 :    3 items \n",
      "cluster #  4 :   52 items \n",
      "cluster #  5 :  242 items \n",
      "cluster #  6 :    2 items \n",
      "cluster #  7 :   96 items \n",
      "cluster #  8 :   17 items \n",
      "cluster #  9 :  130 items \n",
      "cluster # 10 :   39 items \n",
      "cluster # 11 :  218 items \n",
      "cluster # 12 :   16 items \n",
      "cluster # 13 :  208 items \n",
      "cluster # 14 :   63 items \n",
      "cluster # 15 :   68 items \n",
      "cluster # 16 : 1645 items \n",
      "cluster # 17 :  678 items <==\n",
      "cluster # 18 :   16 items \n",
      "cluster # 19 :   63 items \n",
      "cluster # 20 :  104 items \n",
      "cluster # 21 :  153 items \n",
      "cluster # 22 :   31 items \n",
      "cluster # 23 :  956 items \n",
      "cluster # 24 :   41 items \n",
      "cluster # 25 :  116 items \n",
      "cluster # 26 :    1 items \n",
      "cluster # 27 :  723 items \n",
      "cluster # 28 :   43 items \n",
      "cluster # 29 :    9 items \n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = recom.getMovies('아이언맨 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_sum</th>\n",
       "      <th>title</th>\n",
       "      <th>dist_scaled</th>\n",
       "      <th>genre_scaled</th>\n",
       "      <th>wvote_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.924022</td>\n",
       "      <td>아이언맨</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.338062</td>\n",
       "      <td>0.902157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.850839</td>\n",
       "      <td>아이언맨 3</td>\n",
       "      <td>0.825880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.829715</td>\n",
       "      <td>극장판 소드 아트 온라인 -오디널 스케일-</td>\n",
       "      <td>0.884154</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.823917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.806956</td>\n",
       "      <td>배틀필드</td>\n",
       "      <td>0.866502</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>0.621149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.736720</td>\n",
       "      <td>어벤져스: 에이지 오브 울트론</td>\n",
       "      <td>0.756321</td>\n",
       "      <td>0.507093</td>\n",
       "      <td>0.809536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.735313</td>\n",
       "      <td>레지던트 이블</td>\n",
       "      <td>0.749644</td>\n",
       "      <td>0.596285</td>\n",
       "      <td>0.759686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.732973</td>\n",
       "      <td>엑스맨 2 - 엑스투</td>\n",
       "      <td>0.764697</td>\n",
       "      <td>0.507093</td>\n",
       "      <td>0.705062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.714953</td>\n",
       "      <td>수퍼맨 리턴즈</td>\n",
       "      <td>0.736802</td>\n",
       "      <td>0.676123</td>\n",
       "      <td>0.578994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.707564</td>\n",
       "      <td>블랙 팬서</td>\n",
       "      <td>0.752887</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.652545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.704568</td>\n",
       "      <td>기술자들</td>\n",
       "      <td>0.775021</td>\n",
       "      <td>0.258199</td>\n",
       "      <td>0.587317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    weighted_sum                    title  dist_scaled  genre_scaled  \\\n",
       "0       0.924022                     아이언맨     1.000000      0.338062   \n",
       "3       0.850839                   아이언맨 3     0.825880      1.000000   \n",
       "1       0.829715  극장판 소드 아트 온라인 -오디널 스케일-     0.884154      0.400000   \n",
       "2       0.806956                     배틀필드     0.866502      0.516398   \n",
       "13      0.736720         어벤져스: 에이지 오브 울트론     0.756321      0.507093   \n",
       "18      0.735313                  레지던트 이블     0.749644      0.596285   \n",
       "9       0.732973              엑스맨 2 - 엑스투     0.764697      0.507093   \n",
       "25      0.714953                  수퍼맨 리턴즈     0.736802      0.676123   \n",
       "16      0.707564                    블랙 팬서     0.752887      0.400000   \n",
       "6       0.704568                     기술자들     0.775021      0.258199   \n",
       "\n",
       "    wvote_scaled  \n",
       "0       0.902157  \n",
       "3       0.901343  \n",
       "1       0.823917  \n",
       "2       0.621149  \n",
       "13      0.809536  \n",
       "18      0.759686  \n",
       "9       0.705062  \n",
       "25      0.578994  \n",
       "16      0.652545  \n",
       "6       0.587317  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[['weighted_sum','title','dist_scaled','genre_scaled','wvote_scaled']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
